# ğŸš€ Azure End-to-End Data Engineering Pipeline  

![Azure](https://img.shields.io/badge/Azure-Data%20Engineering-blue)  
![Databricks](https://img.shields.io/badge/Databricks-Lakehouse-orange)  
![ETL](https://img.shields.io/badge/ETL-Pipeline-green)  
![PowerBI](https://img.shields.io/badge/PowerBI-Dashboard-yellow)  

---

## ğŸ“Œ Project Overview  
This project demonstrates the design and implementation of a **real-world Azure Data Engineering pipeline**.  
It integrates **Azure SQL Database, Azure Data Factory (ADF), Azure Data Lake, Databricks, Delta Lake, Unity Catalog, and Power BI** under the **Medallion Architecture** (Bronze â Silver â Gold).  

---

## âœ¨ Key Highlights  
- âš¡ **Incremental data ingestion** using **Change Data Capture (CDC)**  
- ğŸ—‚ï¸ **Star schema modeling** (Facts & Dimensions)  
- ğŸ”„ **Slowly Changing Dimensions (SCD Type 1)** handling  
- ğŸ”‘ **Parameterized pipelines** for scalable deployment  
- ğŸ” **Data governance, lineage, and schema enforcement** with Unity Catalog  
- ğŸ“Š **Power BI dashboards** for visualization  

---

## ğŸ—ï¸ Architecture  

<p align="center">
  <img src="https://raw.githubusercontent.com/tkaushik015/Enterprise-Data-Governance-and-Analytics-Framework/main/architecture.png" width="800"/>
</p>  

The pipeline follows a **layered Medallion Architecture**:  

1. **Data Source** â†’ Azure SQL Database  
   - Source tables hosted in Azure SQL DB  
   - Both **initial** and **incremental loads** staged  

2. **Ingestion Layer (Bronze)** â†’ Azure Data Factory  
   - Data extracted into **Azure Data Lake (Bronze)**  
   - Stored in **Parquet format** for efficiency  
   - Incremental ingestion: only new/updated records  

3. **Transformation Layer (Silver)** â†’ Azure Databricks  
   - Data cleaning, joins, and transformations with **PySpark**  
   - Creation of **dimension & fact tables**  
   - Implementation of **SCD Type 1**  

4. **Serving Layer (Gold)** â†’ Delta Lake  
   - Modeled **star schema** for analytics  
   - Optimized storage for reporting  

5. **Governance & Security** â†’ Unity Catalog  
   - Lineage tracking, schema enforcement, access control  

6. **Visualization** â†’ Power BI  
   - Dashboards for KPIs, business insights, and reporting  

---

## ğŸ”„ Data Flow  

ğŸ“¥ **Data Source**: Azure SQL DB  
â¬‡ï¸  
ğŸ“¦ **Bronze**: Raw ingested data via ADF (Parquet)  
â¬‡ï¸  
ğŸ§¹ **Silver**: Cleaned, enriched data in Databricks (SCD, transformations)  
â¬‡ï¸  
â­ **Gold**: Business-ready data (Facts & Dimensions)  
â¬‡ï¸  
ğŸ“Š **Power BI**: Interactive dashboards  

---

## ğŸ›  Data Pipeline Flow  

ğŸ“‚ SQL DB
â¬‡ï¸ Extracted via ADF â†’ Bronze Layer (raw data, stored in Parquet)

â¬‡ï¸ Cleaned & transformed in Databricks â†’ Silver Layer (joins, deduplication, business rules)

â¬‡ï¸ Modeled into Gold Layer (âœ… Facts & Dimensions with Star Schema)

â¬‡ï¸ Governed with Unity Catalog (ğŸ” schema enforcement, lineage, data governance)

â¬‡ï¸ Visualized in Power BI Dashboards (ğŸ“Š KPIs, trends, business insights)
